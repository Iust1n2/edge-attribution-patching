{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_257450/3208339110.py:8: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic('load_ext autoreload')\n",
      "/tmp/ipykernel_257450/3208339110.py:9: DeprecationWarning: `magic(...)` is deprecated since IPython 0.13 (warning added in 8.1), use run_line_magic(magic_name, parameter_s).\n",
      "  ipython.magic('autoreload 2')\n",
      "/home/iustin/.conda/envs/eap/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "sys.path.append('../../Automatic-Circuit-Discovery/')\n",
    "import IPython\n",
    "ipython = get_ipython()\n",
    "if ipython is not None:\n",
    "    ipython.magic('load_ext autoreload')\n",
    "    ipython.magic('autoreload 2')\n",
    "import torch as t\n",
    "from torch import Tensor\n",
    "\n",
    "from acdc.hybridretrieval.utils import (\n",
    "    get_all_hybrid_retrieval_things,\n",
    "    get_gpt2_small\n",
    ")\n",
    "\n",
    "from transformer_lens import HookedTransformer, ActivationCache\n",
    "\n",
    "import tqdm.notebook as tqdm\n",
    "import plotly\n",
    "\n",
    "device = t.device(\"cuda\" if t.cuda.is_available() else \"CPU\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2 into HookedTransformer\n",
      "Moving model to device:  cuda\n",
      "Clean Prompts:\n",
      "Alice lives in France, Paris - Alice, John lives in Germany, Berlin - John, Peter lives in USA, Washington - Peter\n",
      "Lucy lives in Turkey, Ankara - Lucy, Sara lives in Italy, Rome - Sara, Bob lives in Spain, Madrid - Bob\n",
      "Tom lives in Canada, Toronto - Tom, Anna lives in Australia, Canberra - Anna, Michael lives in Japan, Tokyo - Michael\n",
      "David lives in Brazil, Rio de Janeiro - David, Alice lives in France, Paris - Alice, Peter lives in Germany, Berlin - Peter\n",
      "Sara lives in USA, Washington - Sara, Lucy lives in Turkey, Ankara - Lucy, Tom lives in Italy, Rome - Tom\n",
      "John lives in Spain, Madrid - John, Michael lives in Canada, Toronto - Michael, Anna lives in Australia, Canberra - Anna\n",
      "David lives in Japan, Tokyo - David, Sara lives in Brazil, Rio de Janeiro - Sara, Alice lives in France, Paris - Alice\n",
      "Bob lives in Germany, Berlin - Bob, Peter lives in USA, Washington - Peter, Tom lives in Turkey, Ankara - Tom\n",
      "Anna lives in Italy, Rome - Anna, Tom lives in Spain, Madrid - Tom, David lives in Canada, Toronto - David\n",
      "Michael lives in Australia, Canberra - Michael, John lives in Japan, Tokyo - John, John lives in Brazil, Rio de Janeiro - John\n",
      "Alice lives in France, Paris - Alice, Bob lives in Germany, Berlin - Bob, John lives in USA, Washington - John\n",
      "Peter lives in Turkey, Ankara - Peter, Alice lives in Italy, Rome - Alice, Bob lives in France, Paris - Bob\n",
      "Lucy lives in Spain, Madrid - Lucy, Michael lives in Canada, Toronto - Michael, Tom lives in Australia, Canberra - Tom\n",
      "Anna lives in Japan, Tokyo - Anna, Sara lives in Brazil, Rio de Janeiro - Sara, David lives in France, Paris - David\n",
      "John lives in Germany, Berlin - John, Peter lives in USA, Washington - Peter, Bob lives in Turkey, Ankara - Bob\n",
      "Tom lives in Italy, Rome - Tom, David lives in Spain, Madrid - David, Michael lives in Canada, Toronto - Michael\n",
      "Sara lives in Australia, Canberra - Sara, Alice lives in Japan, Tokyo - Alice, Bob lives in Brazil, Rio de Janeiro - Bob\n",
      "Peter lives in France, Paris - Peter, Lucy lives in Germany, Berlin - Lucy, Tom lives in USA, Washington - Tom\n",
      "David lives in Turkey, Ankara - David, Michael lives in Italy, Rome - Michael, Anna lives in Spain, Madrid - Anna\n",
      "John lives in Canada, Toronto - John, Sara lives in Australia, Canberra - Sara, Alice lives in Japan, Tokyo - Alice\n",
      "\n",
      "Corrupted Prompts:\n",
      "Alice lives in France, Paris - Alice, John lives in Germany, Berlin - John, Peter lives in Spain, Washington - Peter\n",
      "Lucy lives in Turkey, Ankara - Lucy, Sara lives in Italy, Rome - Sara, Bob lives in Spain, Ankara - Bob\n",
      "Tom lives in Canada, Toronto - Tom, Anna lives in Australia, Canberra - Anna, Michael lives in Australia, Tokyo - Michael\n",
      "David lives in Brazil, Rio de Janeiro - David, Alice lives in France, Paris - Alice, Peter lives in Germany, Bucharest - Peter\n",
      "Sara lives in USA, Washington - Sara, Lucy lives in Turkey, Ankara - Lucy, Tom lives in Canada, Rome - Tom\n",
      "John lives in Spain, Madrid - John, Michael lives in Canada, Toronto - Michael, Anna lives in Australia, Toronto - Anna\n",
      "David lives in Japan, Tokyo - David, Sara lives in Brazil, Rio de Janeiro - Sara, Alice lives in Brazil, Paris - Alice\n",
      "Bob lives in Germany, Berlin - Bob, Peter lives in USA, Washington - Peter, Tom lives in Turkey, Sofia - Tom\n",
      "Anna lives in Italy, Rome - Anna, Tom lives in Spain, Madrid - Tom, David lives in Spain, Toronto - David\n",
      "Michael lives in Australia, Canberra - Michael, John lives in Japan, Tokyo - John, John lives in Brazil, Tirana - John\n",
      "Alice lives in France, Paris - Alice, Bob lives in Germany, Berlin - Bob, John lives in Japan, Washington - John\n",
      "Peter lives in Turkey, Ankara - Peter, Alice lives in Italy, Rome - Alice, Bob lives in France, Milan - Bob\n",
      "Lucy lives in Spain, Madrid - Lucy, Michael lives in Canada, Toronto - Michael, Tom lives in Portugal, Canberra - Tom\n",
      "Anna lives in Japan, Tokyo - Anna, Sara lives in Brazil, Rio de Janeiro - Sara, David lives in France, Los Angeles - David\n",
      "John lives in Germany, Berlin - John, Peter lives in USA, Washington - Peter, Bob lives in Germany, Ankara - Bob\n",
      "Tom lives in Italy, Rome - Tom, David lives in Spain, Madrid - David, Michael lives in Canada, California - Michael\n",
      "Sara lives in Australia, Canberra - Sara, Alice lives in Japan, Tokyo - Alice, Bob lives in Venezuela, Rio de Janeiro - Bob\n",
      "Peter lives in France, Paris - Peter, Lucy lives in Germany, Berlin - Lucy, Tom lives in USA, Medellin - Tom\n",
      "David lives in Turkey, Ankara - David, Michael lives in Italy, Rome - Michael, Anna lives in Italy, Madrid - Anna\n",
      "John lives in Canada, Toronto - John, Sara lives in Australia, Canberra - Sara, Alice lives in Japan, Canberra - Alice\n",
      "Clean Data Datasets:\n",
      "torch.Size([20, 29])\n",
      "\n",
      "Corrupted Data Datasets:\n",
      "torch.Size([20, 29])\n",
      "\n",
      "Clean Labels shape:\n",
      "torch.Size([20, 1])\n",
      "\n",
      "Clean Wrong Labels shape:\n",
      "torch.Size([20, 1])\n",
      "Shape of validation_data: torch.Size([10, 29])\n",
      "Shape of validation_patch_data: torch.Size([10, 29])\n",
      "Shape of test_data: torch.Size([10, 29])\n",
      "Shape of test_patch_data: torch.Size([10, 29])\n"
     ]
    }
   ],
   "source": [
    "all_kbicr_items = get_all_hybrid_retrieval_things(num_examples=20, device=device, metric_name='logit_diff')\n",
    "\n",
    "tl_model = all_kbicr_items.tl_model\n",
    "validation_metric = all_kbicr_items.validation_metric\n",
    "validation_data = all_kbicr_items.validation_data\n",
    "validation_labels = all_kbicr_items.validation_labels\n",
    "validation_patch_data = all_kbicr_items.validation_patch_data\n",
    "test_metrics = all_kbicr_items.test_metrics\n",
    "test_data = all_kbicr_items.test_data\n",
    "test_labels = all_kbicr_items.test_labels\n",
    "test_patch_data = all_kbicr_items.test_patch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model gpt2-small into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "model = HookedTransformer.from_pretrained(\n",
    "    'gpt2-small',\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    ")\n",
    "model.set_use_hook_mlp_in(True)\n",
    "model.set_use_split_qkv_input(True)\n",
    "model.set_use_attn_result(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_kbicr_metric(logits):\n",
    "    return -abs(test_metrics['logit_diff'](logits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/iustin/Mech-Interp/Automatic-Circuit-Discovery'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/iustin/Mech-Interp/edge-attribution-patching'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir('../edge-attribution-patching')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n",
      "WARNING:root:cache_all is deprecated and will eventually be removed, use add_caching_hooks or run_with_cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ln_final.hook_normalized\n",
      "ln_final.hook_scale\n",
      "blocks.11.hook_resid_post\n",
      "blocks.11.hook_mlp_out\n",
      "blocks.11.mlp.hook_post\n",
      "blocks.11.mlp.hook_pre\n",
      "blocks.11.ln2.hook_normalized\n",
      "blocks.11.ln2.hook_scale\n",
      "blocks.11.hook_mlp_in\n",
      "blocks.11.hook_resid_mid\n",
      "blocks.11.hook_attn_out\n",
      "blocks.11.attn.hook_result\n",
      "blocks.11.attn.hook_z\n",
      "blocks.11.attn.hook_pattern\n",
      "blocks.11.attn.hook_attn_scores\n",
      "blocks.11.attn.hook_v\n",
      "blocks.11.attn.hook_k\n",
      "blocks.11.attn.hook_q\n",
      "blocks.11.ln1.hook_normalized\n",
      "blocks.11.ln1.hook_scale\n",
      "blocks.11.hook_v_input\n",
      "blocks.11.hook_k_input\n",
      "blocks.11.hook_q_input\n",
      "blocks.11.hook_resid_pre\n",
      "blocks.10.hook_resid_post\n",
      "blocks.10.hook_mlp_out\n",
      "blocks.10.mlp.hook_post\n",
      "blocks.10.mlp.hook_pre\n",
      "blocks.10.ln2.hook_normalized\n",
      "blocks.10.ln2.hook_scale\n",
      "blocks.10.hook_mlp_in\n",
      "blocks.10.hook_resid_mid\n",
      "blocks.10.hook_attn_out\n",
      "blocks.10.attn.hook_result\n",
      "blocks.10.attn.hook_z\n",
      "blocks.10.attn.hook_pattern\n",
      "blocks.10.attn.hook_attn_scores\n",
      "blocks.10.attn.hook_v\n",
      "blocks.10.attn.hook_k\n",
      "blocks.10.attn.hook_q\n",
      "blocks.10.ln1.hook_normalized\n",
      "blocks.10.ln1.hook_scale\n",
      "blocks.10.hook_v_input\n",
      "blocks.10.hook_k_input\n",
      "blocks.10.hook_q_input\n",
      "blocks.10.hook_resid_pre\n",
      "blocks.9.hook_resid_post\n",
      "blocks.9.hook_mlp_out\n",
      "blocks.9.mlp.hook_post\n",
      "blocks.9.mlp.hook_pre\n",
      "blocks.9.ln2.hook_normalized\n",
      "blocks.9.ln2.hook_scale\n",
      "blocks.9.hook_mlp_in\n",
      "blocks.9.hook_resid_mid\n",
      "blocks.9.hook_attn_out\n",
      "blocks.9.attn.hook_result\n",
      "blocks.9.attn.hook_z\n",
      "blocks.9.attn.hook_pattern\n",
      "blocks.9.attn.hook_attn_scores\n",
      "blocks.9.attn.hook_v\n",
      "blocks.9.attn.hook_k\n",
      "blocks.9.attn.hook_q\n",
      "blocks.9.ln1.hook_normalized\n",
      "blocks.9.ln1.hook_scale\n",
      "blocks.9.hook_v_input\n",
      "blocks.9.hook_k_input\n",
      "blocks.9.hook_q_input\n",
      "blocks.9.hook_resid_pre\n",
      "blocks.8.hook_resid_post\n",
      "blocks.8.hook_mlp_out\n",
      "blocks.8.mlp.hook_post\n",
      "blocks.8.mlp.hook_pre\n",
      "blocks.8.ln2.hook_normalized\n",
      "blocks.8.ln2.hook_scale\n",
      "blocks.8.hook_mlp_in\n",
      "blocks.8.hook_resid_mid\n",
      "blocks.8.hook_attn_out\n",
      "blocks.8.attn.hook_result\n",
      "blocks.8.attn.hook_z\n",
      "blocks.8.attn.hook_pattern\n",
      "blocks.8.attn.hook_attn_scores\n",
      "blocks.8.attn.hook_v\n",
      "blocks.8.attn.hook_k\n",
      "blocks.8.attn.hook_q\n",
      "blocks.8.ln1.hook_normalized\n",
      "blocks.8.ln1.hook_scale\n",
      "blocks.8.hook_v_input\n",
      "blocks.8.hook_k_input\n",
      "blocks.8.hook_q_input\n",
      "blocks.8.hook_resid_pre\n",
      "blocks.7.hook_resid_post\n",
      "blocks.7.hook_mlp_out\n",
      "blocks.7.mlp.hook_post\n",
      "blocks.7.mlp.hook_pre\n",
      "blocks.7.ln2.hook_normalized\n",
      "blocks.7.ln2.hook_scale\n",
      "blocks.7.hook_mlp_in\n",
      "blocks.7.hook_resid_mid\n",
      "blocks.7.hook_attn_out\n",
      "blocks.7.attn.hook_result\n",
      "blocks.7.attn.hook_z\n",
      "blocks.7.attn.hook_pattern\n",
      "blocks.7.attn.hook_attn_scores\n",
      "blocks.7.attn.hook_v\n",
      "blocks.7.attn.hook_k\n",
      "blocks.7.attn.hook_q\n",
      "blocks.7.ln1.hook_normalized\n",
      "blocks.7.ln1.hook_scale\n",
      "blocks.7.hook_v_input\n",
      "blocks.7.hook_k_input\n",
      "blocks.7.hook_q_input\n",
      "blocks.7.hook_resid_pre\n",
      "blocks.6.hook_resid_post\n",
      "blocks.6.hook_mlp_out\n",
      "blocks.6.mlp.hook_post\n",
      "blocks.6.mlp.hook_pre\n",
      "blocks.6.ln2.hook_normalized\n",
      "blocks.6.ln2.hook_scale\n",
      "blocks.6.hook_mlp_in\n",
      "blocks.6.hook_resid_mid\n",
      "blocks.6.hook_attn_out\n",
      "blocks.6.attn.hook_result\n",
      "blocks.6.attn.hook_z\n",
      "blocks.6.attn.hook_pattern\n",
      "blocks.6.attn.hook_attn_scores\n",
      "blocks.6.attn.hook_v\n",
      "blocks.6.attn.hook_k\n",
      "blocks.6.attn.hook_q\n",
      "blocks.6.ln1.hook_normalized\n",
      "blocks.6.ln1.hook_scale\n",
      "blocks.6.hook_v_input\n",
      "blocks.6.hook_k_input\n",
      "blocks.6.hook_q_input\n",
      "blocks.6.hook_resid_pre\n",
      "blocks.5.hook_resid_post\n",
      "blocks.5.hook_mlp_out\n",
      "blocks.5.mlp.hook_post\n",
      "blocks.5.mlp.hook_pre\n",
      "blocks.5.ln2.hook_normalized\n",
      "blocks.5.ln2.hook_scale\n",
      "blocks.5.hook_mlp_in\n",
      "blocks.5.hook_resid_mid\n",
      "blocks.5.hook_attn_out\n",
      "blocks.5.attn.hook_result\n",
      "blocks.5.attn.hook_z\n",
      "blocks.5.attn.hook_pattern\n",
      "blocks.5.attn.hook_attn_scores\n",
      "blocks.5.attn.hook_v\n",
      "blocks.5.attn.hook_k\n",
      "blocks.5.attn.hook_q\n",
      "blocks.5.ln1.hook_normalized\n",
      "blocks.5.ln1.hook_scale\n",
      "blocks.5.hook_v_input\n",
      "blocks.5.hook_k_input\n",
      "blocks.5.hook_q_input\n",
      "blocks.5.hook_resid_pre\n",
      "blocks.4.hook_resid_post\n",
      "blocks.4.hook_mlp_out\n",
      "blocks.4.mlp.hook_post\n",
      "blocks.4.mlp.hook_pre\n",
      "blocks.4.ln2.hook_normalized\n",
      "blocks.4.ln2.hook_scale\n",
      "blocks.4.hook_mlp_in\n",
      "blocks.4.hook_resid_mid\n",
      "blocks.4.hook_attn_out\n",
      "blocks.4.attn.hook_result\n",
      "blocks.4.attn.hook_z\n",
      "blocks.4.attn.hook_pattern\n",
      "blocks.4.attn.hook_attn_scores\n",
      "blocks.4.attn.hook_v\n",
      "blocks.4.attn.hook_k\n",
      "blocks.4.attn.hook_q\n",
      "blocks.4.ln1.hook_normalized\n",
      "blocks.4.ln1.hook_scale\n",
      "blocks.4.hook_v_input\n",
      "blocks.4.hook_k_input\n",
      "blocks.4.hook_q_input\n",
      "blocks.4.hook_resid_pre\n",
      "blocks.3.hook_resid_post\n",
      "blocks.3.hook_mlp_out\n",
      "blocks.3.mlp.hook_post\n",
      "blocks.3.mlp.hook_pre\n",
      "blocks.3.ln2.hook_normalized\n",
      "blocks.3.ln2.hook_scale\n",
      "blocks.3.hook_mlp_in\n",
      "blocks.3.hook_resid_mid\n",
      "blocks.3.hook_attn_out\n",
      "blocks.3.attn.hook_result\n",
      "blocks.3.attn.hook_z\n",
      "blocks.3.attn.hook_pattern\n",
      "blocks.3.attn.hook_attn_scores\n",
      "blocks.3.attn.hook_v\n",
      "blocks.3.attn.hook_k\n",
      "blocks.3.attn.hook_q\n",
      "blocks.3.ln1.hook_normalized\n",
      "blocks.3.ln1.hook_scale\n",
      "blocks.3.hook_v_input\n",
      "blocks.3.hook_k_input\n",
      "blocks.3.hook_q_input\n",
      "blocks.3.hook_resid_pre\n",
      "blocks.2.hook_resid_post\n",
      "blocks.2.hook_mlp_out\n",
      "blocks.2.mlp.hook_post\n",
      "blocks.2.mlp.hook_pre\n",
      "blocks.2.ln2.hook_normalized\n",
      "blocks.2.ln2.hook_scale\n",
      "blocks.2.hook_mlp_in\n",
      "blocks.2.hook_resid_mid\n",
      "blocks.2.hook_attn_out\n",
      "blocks.2.attn.hook_result\n",
      "blocks.2.attn.hook_z\n",
      "blocks.2.attn.hook_pattern\n",
      "blocks.2.attn.hook_attn_scores\n",
      "blocks.2.attn.hook_v\n",
      "blocks.2.attn.hook_k\n",
      "blocks.2.attn.hook_q\n",
      "blocks.2.ln1.hook_normalized\n",
      "blocks.2.ln1.hook_scale\n",
      "blocks.2.hook_v_input\n",
      "blocks.2.hook_k_input\n",
      "blocks.2.hook_q_input\n",
      "blocks.2.hook_resid_pre\n",
      "blocks.1.hook_resid_post\n",
      "blocks.1.hook_mlp_out\n",
      "blocks.1.mlp.hook_post\n",
      "blocks.1.mlp.hook_pre\n",
      "blocks.1.ln2.hook_normalized\n",
      "blocks.1.ln2.hook_scale\n",
      "blocks.1.hook_mlp_in\n",
      "blocks.1.hook_resid_mid\n",
      "blocks.1.hook_attn_out\n",
      "blocks.1.attn.hook_result\n",
      "blocks.1.attn.hook_z\n",
      "blocks.1.attn.hook_pattern\n",
      "blocks.1.attn.hook_attn_scores\n",
      "blocks.1.attn.hook_v\n",
      "blocks.1.attn.hook_k\n",
      "blocks.1.attn.hook_q\n",
      "blocks.1.ln1.hook_normalized\n",
      "blocks.1.ln1.hook_scale\n",
      "blocks.1.hook_v_input\n",
      "blocks.1.hook_k_input\n",
      "blocks.1.hook_q_input\n",
      "blocks.1.hook_resid_pre\n",
      "blocks.0.hook_resid_post\n",
      "blocks.0.hook_mlp_out\n",
      "blocks.0.mlp.hook_post\n",
      "blocks.0.mlp.hook_pre\n",
      "blocks.0.ln2.hook_normalized\n",
      "blocks.0.ln2.hook_scale\n",
      "blocks.0.hook_mlp_in\n",
      "blocks.0.hook_resid_mid\n",
      "blocks.0.hook_attn_out\n",
      "blocks.0.attn.hook_result\n",
      "blocks.0.attn.hook_z\n",
      "blocks.0.attn.hook_pattern\n",
      "blocks.0.attn.hook_attn_scores\n",
      "blocks.0.attn.hook_v\n",
      "blocks.0.attn.hook_k\n",
      "blocks.0.attn.hook_q\n",
      "blocks.0.ln1.hook_normalized\n",
      "blocks.0.ln1.hook_scale\n",
      "blocks.0.hook_v_input\n",
      "blocks.0.hook_k_input\n",
      "blocks.0.hook_q_input\n",
      "blocks.0.hook_resid_pre\n",
      "hook_pos_embed\n",
      "hook_embed\n",
      "self.current_node=TLACDCInterpNode(blocks.11.hook_resid_post, [:])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 7.38 MiB is free. Including non-PyTorch memory, this process has 7.77 GiB memory in use. Of the allocated memory 6.81 GiB is allocated by PyTorch, and 791.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 22\u001b[0m\n\u001b[1;32m      7\u001b[0m RUN_NAME \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabs_edges\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      8\u001b[0m acdcpp_exp \u001b[38;5;241m=\u001b[39m ACDCPPExperiment(\n\u001b[1;32m      9\u001b[0m     tl_model,\n\u001b[1;32m     10\u001b[0m     test_data,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     no_pruned_nodes_attr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m     21\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m pruned_heads, num_passes, pruned_attrs \u001b[38;5;241m=\u001b[39m \u001b[43macdcpp_exp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Mech-Interp/edge-attribution-patching/ACDCPPExperiment.py:132\u001b[0m, in \u001b[0;36mACDCPPExperiment.run\u001b[0;34m(self, save_after_acdcpp, save_after_acdc)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mthresholds):\n\u001b[1;32m    131\u001b[0m     exp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetup_exp(threshold)\n\u001b[0;32m--> 132\u001b[0m     acdcpp_heads, attrs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_acdcpp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Only applying threshold to this one as these graphs tend to be HUGE\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m threshold \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_graphs_after:\n",
      "File \u001b[0;32m~/Mech-Interp/edge-attribution-patching/ACDCPPExperiment.py:100\u001b[0m, in \u001b[0;36mACDCPPExperiment.run_acdcpp\u001b[0;34m(self, exp, threshold)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRunning ACDC++\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_pruned_nodes_attr):\n\u001b[0;32m--> 100\u001b[0m     pruned_nodes_attr \u001b[38;5;241m=\u001b[39m \u001b[43macdc_nodes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclean_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcorrupted_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macdcpp_metric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    107\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattr_absolute_val\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattr_absolute_val\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpruning_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     t\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (get_nodes(exp\u001b[38;5;241m.\u001b[39mcorr), pruned_nodes_attr)\n",
      "File \u001b[0;32m~/Mech-Interp/edge-attribution-patching/utils/prune_utils.py:203\u001b[0m, in \u001b[0;36macdc_nodes\u001b[0;34m(model, clean_input, corrupted_input, metric, threshold, exp, verbose, attr_absolute_val, mode)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03mRuns attribution-patching-based ACDC on the model, using the given metric and data.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03mReturns the pruned model, and which heads were pruned.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03m    attr_absolute_val: whether to take the absolute value of the attribution before thresholding\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;66;03m# get the 2 fwd and 1 bwd caches; cache \"normalized\" and \"result\" of attn layers\u001b[39;00m\n\u001b[0;32m--> 203\u001b[0m clean_cache, corrupted_cache, clean_grad_cache \u001b[38;5;241m=\u001b[39m \u001b[43mget_3_caches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorrupted_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;66;03m# compute first-order Taylor approximation for each node to get the attribution\u001b[39;00m\n\u001b[1;32m    206\u001b[0m     clean_head_act \u001b[38;5;241m=\u001b[39m clean_cache\u001b[38;5;241m.\u001b[39mstack_head_results()\n",
      "File \u001b[0;32m~/Mech-Interp/edge-attribution-patching/utils/prune_utils.py:142\u001b[0m, in \u001b[0;36mget_3_caches\u001b[0;34m(model, clean_input, corrupted_input, metric, mode)\u001b[0m\n\u001b[1;32m    139\u001b[0m     corrupted_cache[hook\u001b[38;5;241m.\u001b[39mname] \u001b[38;5;241m=\u001b[39m act\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[1;32m    141\u001b[0m model\u001b[38;5;241m.\u001b[39madd_hook(hook_filter \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnode\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m edge_acdcpp_outgoing_filter, forward_corrupted_cache_hook, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfwd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 142\u001b[0m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorrupted_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m model\u001b[38;5;241m.\u001b[39mreset_hooks()\n\u001b[1;32m    145\u001b[0m clean_cache \u001b[38;5;241m=\u001b[39m ActivationCache(clean_cache, model)\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:546\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, left_attention_mask, stop_at_layer, past_kv_cache, past_left_attention_mask)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    542\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    543\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    544\u001b[0m         )\n\u001b[0;32m--> 546\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[1;32m    552\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    553\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    554\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    557\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    558\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    559\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/transformer_lens/components.py:1070\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, left_attention_mask)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1059\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m   1061\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_attn_out(\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m   1066\u001b[0m         query_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(query_input)\n\u001b[1;32m   1067\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[1;32m   1068\u001b[0m         key_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1(key_input)\n\u001b[1;32m   1069\u001b[0m         \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m0.0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m shortformer_pos_embed),\n\u001b[0;32m-> 1070\u001b[0m         value_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   1071\u001b[0m         past_kv_cache_entry\u001b[38;5;241m=\u001b[39mpast_kv_cache_entry,\n\u001b[1;32m   1072\u001b[0m         left_attention_mask\u001b[38;5;241m=\u001b[39mleft_attention_mask,\n\u001b[1;32m   1073\u001b[0m     )\n\u001b[1;32m   1074\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mattn_only \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mparallel_attn_mlp:\n\u001b[1;32m   1076\u001b[0m     resid_mid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_resid_mid(\n\u001b[1;32m   1077\u001b[0m         resid_pre \u001b[38;5;241m+\u001b[39m attn_out\n\u001b[1;32m   1078\u001b[0m     )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/eap/lib/python3.10/site-packages/transformer_lens/components.py:281\u001b[0m, in \u001b[0;36mLayerNormPre.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    275\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m    277\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m-\u001b[39m x\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# [batch, pos, length]\u001b[39;00m\n\u001b[1;32m    278\u001b[0m scale: Union[\n\u001b[1;32m    279\u001b[0m     Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos 1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    280\u001b[0m     Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos head_index 1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m--> 281\u001b[0m ] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_scale((\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mmean(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps)\u001b[38;5;241m.\u001b[39msqrt())\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_normalized(x \u001b[38;5;241m/\u001b[39m scale)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39mdtype)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB. GPU 0 has a total capacty of 7.79 GiB of which 7.38 MiB is free. Including non-PyTorch memory, this process has 7.77 GiB memory in use. Of the allocated memory 6.81 GiB is allocated by PyTorch, and 791.11 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from ACDCPPExperiment import ACDCPPExperiment\n",
    "import numpy as np\n",
    "THRESHOLDS = [0.09] # np.arange(0.04, 0.16, 0.005)\n",
    "# I'm just using one threshold so I can move fast!\n",
    "\n",
    "tl_model.reset_hooks()\n",
    "RUN_NAME = 'abs_edges'\n",
    "acdcpp_exp = ACDCPPExperiment(\n",
    "    tl_model,\n",
    "    test_data,\n",
    "    test_patch_data,\n",
    "    test_metrics['logit_diff'],\n",
    "    abs_kbicr_metric,\n",
    "    THRESHOLDS,\n",
    "    # run_name=RUN_NAME,\n",
    "    verbose=False,\n",
    "    attr_absolute_val=True,\n",
    "    save_graphs_after=0,\n",
    "    pruning_mode='edge',\n",
    "    no_pruned_nodes_attr=1,\n",
    ")\n",
    "pruned_heads, num_passes, pruned_attrs = acdcpp_exp.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
